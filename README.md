# ğŸ¤– Jarvis AI Assistant

## âœ¨ What's New in v2.0

- ğŸ—ï¸ **Clean Architecture**: Proper separation of concerns, modular design
- ğŸ§¹ **Project Cleanup**: Removed 20+ old files, organized structure
- ğŸ§  **Smart Model Routing**: phi3 for quick chats, llama3.1 for complex topics

## ğŸ­ Available Personalities
- `iron_man_jarvis` - Sophisticated, witty, calls you "sir"
- `professional` - Helpful and concise
- `friendly` - Warm and conversational

## ğŸ§  Smart Model Routing

Jarvis automatically selects the optimal AI model based on your conversation:

### âš¡ **Quick Mode (phi3)**
**Used for:**
- Simple greetings: "Hello Jarvis"
- Basic questions: "What time is it?"
- Short conversations: "How are you?"
- Quick commands: "Thanks!" 

**Benefits:** Fast response (~1-2 seconds), low resource usage

### ğŸ§  **Smart Mode (llama3.1)** 
**Used for:**
- Complex topics: "Explain quantum computing"
- Technical questions: "How does machine learning work?"
- Detailed requests: "Write a plan for learning Python"
- Analysis: "Compare different programming languages"
- Creative tasks: "Help me brainstorm ideas"

**Benefits:** Deep understanding, detailed responses, better reasoning

### ğŸ”§ **Manual Override**
You can force a specific model:
- "Use smart mode" - Switch to llama3.1
- "Use fast mode" - Switch to phi3
- "Status report" - See current model

## ğŸ“ Clean Project Structure

```
jarvis/
â”œâ”€â”€ ğŸ¤– jarvis_clean.py          # Main implementation (RECOMMENDED)
â”œâ”€â”€ ğŸš€ main.py                  # Alternative entry point
â”œâ”€â”€ âš™ï¸  config/                 # Configuration system
â”œâ”€â”€ ğŸ“¦ src/                     # Source code modules  
â”œâ”€â”€ ğŸ“š docs/                    # Documentation
â”œâ”€â”€ ğŸ—ƒï¸  archive/                # Archived old files
â”œâ”€â”€ ğŸ“‹ requirements.txt         # Dependencies
â””â”€â”€ ğŸš€ run_jarvis.bat          # Quick launcher
```

## ğŸŒŸ Key Improvements
- ğŸš€ **Simplified Codebase**: One main file instead of 15+ scattered files  
- ğŸ§  **Smart Model Routing**: phi3 for quick chats, llama3.1 for complex topics
- ğŸ”§ **Better Configuration**: Centralized settings with personality options
- ğŸ¯ **LangChain Ready**: Foundation for advanced LangChain integration
- ğŸ“¦ **Organized Structure**: Professional project layout
- ğŸ§¹ **Zero Clutter**: Old files archived, clean workspace

## ğŸŒŸ Features

- ğŸ¤ **Speech Recognition**: OpenAI Whisper for accurate transcription
- ğŸ§  **Smart AI Routing**: Automatically selects best model for each conversation
  - âš¡ **phi3** (2.2GB) - Quick responses for simple conversations
  - ğŸ§  **llama3.1** (4.9GB) - Deep analysis for complex topics
- ğŸ¤– **AI Conversations**: Local LLM via Ollama (private & fast)
- ğŸ—£ï¸ **Text-to-Speech**: Natural voice responsestant v2.0

**Clean Architecture** | **LangChain Ready** | **Ollama Integration**

A modern, well-structured voice assistant with intelligent AI responses powered by local LLM via Ollama.

## âœ¨ What's New in v2.0

- ğŸ—ï¸ **Clean Architecture**: Proper separation of concerns, modular design
- ğŸš€ **Simplified Codebase**: One main file instead of 15+ scattered files  
- ğŸ”§ **Better Configuration**: Centralized settings with personality options
- ğŸ¯ **LangChain Ready**: Foundation for advanced LangChain integration
- ğŸ“¦ **Organized Structure**: Professional project layout
- ğŸ§¹ **Zero Clutter**: Old files archived, clean workspace

## ï¿½ Features

- ğŸ¤ **Speech Recognition**: OpenAI Whisper for accurate transcription
- ğŸ¤– **AI Conversations**: Local Llama 3.1 via Ollama (private & fast)
- ğŸ—£ï¸ **Text-to-Speech**: Natural voice responses  
- ğŸ­ **Personalities**: Iron Man Jarvis, Professional, or Friendly modes
- ğŸ”„ **Graceful Fallbacks**: Works even when AI is offline
- ğŸ’¬ **Memory**: Remembers conversation contextVoice Assistant

A Python class that can listen for speech, convert it to text using OpenAI's Whisper, and respond with text-to-speech. Specifically responds to "Hello Jarvis" with "Hello sir, how can I help you?"

## ğŸŒŸ Features

- ğŸ¤ **Speech Recognition**: Uses OpenAI's Whisper for accurate speech-to-text
- ï¿½ï¸ **Text-to-Speech**: Natural voice responses using pyttsx3
- ğŸ¤– **Jarvis Response**: Says "Hello sir, how can I help you?" when you say "Hello Jarvis"
- â° **Time Queries**: Ask "What time is it?"
- ğŸ’¬ **Basic Conversation**: Responds to greetings and thanks
- ğŸ”„ **Two Modes**: Interactive (press Enter) or Continuous listening

## ğŸš€ Quick Start

**Easy launcher (recommended):**
```cmd
Double-click: run_jarvis.bat
```

**Manual start:**
```cmd
# 1. Start Ollama (for AI features):
ollama serve

# 2. Run Jarvis:
python jarvis_clean.py

# Or with options:
python jarvis_clean.py --personality iron_man_jarvis --mode continuous
```

**Available personalities:**
- `iron_man_jarvis` - Sophisticated, witty, calls you "sir"
- `professional` - Helpful and concise
- `friendly` - Warm and conversational

## ï¿½ Project Structure

```
ğŸ“ Jarvis/
â”œâ”€â”€ ğŸš€ jarvis_clean.py      # Main implementation (clean & simple)
â”œâ”€â”€ âš™ï¸  main.py             # Advanced entry point (LangChain ready)
â”œâ”€â”€ ğŸ¯ run_jarvis.bat       # Windows launcher
â”œâ”€â”€ ğŸ“‹ requirements.txt     # Dependencies
â”œâ”€â”€ ğŸ“– README.md           # This file
â”œâ”€â”€ ğŸ“ config/             # Configuration system
â”œâ”€â”€ ğŸ“ src/                # Source code (modular architecture)
â”œâ”€â”€ ğŸ“ tests/              # Test files
â”œâ”€â”€ ğŸ“ docs/               # Documentation
â””â”€â”€ ğŸ“ archive/            # Old files (archived for cleanup)
```

## ğŸ¯ How to Use

1. **Start Ollama** (in a separate terminal):
   ```cmd
   ollama serve
   ```

2. **Launch Jarvis**:
   ```cmd
   Double-click run_jarvis.bat
   # OR
   python jarvis_with_ollama.py
   ```

3. **Choose your mode**:
   - **Interactive Mode**: Press Enter when you want to speak
   - **Continuous Mode**: Jarvis listens automatically

4. **Try these conversations**:
   - "Hello Jarvis, how are you?" â†’ AI-powered response
   - "Tell me about artificial intelligence" â†’ Detailed explanation
   - "What should I cook for dinner?" â†’ Helpful suggestions
   - "Thank you" â†’ Polite response
   - "Goodbye" â†’ Stops Jarvis

## ğŸ¤– AI vs Basic Mode

**With Ollama (AI Mode)**:
- Intelligent, contextual responses
- Can discuss complex topics
- Learns from conversation context
- Powered by Llama 3.1

**Without Ollama (Basic Mode)**:
- Simple predefined responses
- "Hello sir, how can I help you?"
- Time queries, basic greetings
- Fallback when Ollama is unavailable

## ğŸ’» Code Examples

### Basic Usage
```python
from jarvis_with_ollama import JarvisWithOllama

# Create Jarvis with AI
jarvis = JarvisWithOllama(ollama_model="llama3.1")

# Single interaction
jarvis.run_once()

# Interactive mode
jarvis.run_interactive()
```

### Custom AI Integration
```python
# Test Ollama connection
from jarvis_with_ollama import OllamaClient

client = OllamaClient(model="llama3.1")
if client.is_available():
    response = client.chat("Hello Jarvis!")
    print(response)
```

## Troubleshooting

### Common Issues

1. **Microphone not detected**:
   - Ensure your microphone is connected and working
   - Check Windows audio settings
   - Try running `python -c "import speech_recognition as sr; print(sr.Microphone.list_microphone_names())"`

2. **PyAudio installation issues**:
   - On Windows, try: `pip install pipwin` then `pipwin install pyaudio`
   - Or download the appropriate wheel from [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio)

3. **Whisper model loading slow**:
   - First run downloads the model, subsequent runs are faster
   - Use smaller models ("tiny" or "base") for faster loading

4. **Speech recognition not working**:
   - Speak clearly and closer to the microphone
   - Reduce background noise
   - Try adjusting the microphone sensitivity

## System Requirements

- **Python**: 3.7 or higher
- **OS**: Windows, macOS, or Linux
- **Hardware**: Microphone and speakers/headphones
- **Internet**: Required for initial Whisper model download

## Dependencies

- `speech_recognition` - For microphone input handling
- `pyttsx3` - For text-to-speech output
- `openai-whisper` - For accurate speech recognition
- `numpy` - For audio data processing
- `pyaudio` - For microphone access

## License

This project is open source and available under the MIT License.

## Contributing

Feel free to fork this project and submit pull requests for improvements!

---

**Note**: This is a basic implementation. For production use, consider adding error handling, configuration files, and more sophisticated command processing.
